{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Cooking?\n",
    "**Description**: Python script to load and visualize What's Cooking Data\n",
    "**Other sources**: used lemmitization code from @DipayanSinhaRoy https://www.kaggle.com/dipayan/whats-cooking/whatscooking-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from time import time\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training Data\n",
    "Here, I read in the json files using the pandas module's json reader. The columns or features for the training data are: *id*, *cuisine* and *ingredients*. The *ingredients* are the **predictors** and *cuisine* is the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read JSON data using pandas\n",
    "# columns are: id, cuisine, ingredients\n",
    "data  = pd.read_json('train.json')\n",
    "\n",
    "labels = LabelEncoder()\n",
    "labels.fit(data.cuisine)\n",
    "all_classes = labels.classes_\n",
    "num_classes = len(all_classes)\n",
    "\n",
    "# Get numerical labels for ytrain \n",
    "y_train = labels.transform(data.cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.head of             cuisine     id                                        ingredients\n",
       "0             greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1       southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2          filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3            indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4            indian  13162  [black pepper, shallots, cornflour, cayenne pe...\n",
       "5          jamaican   6602  [plain flour, sugar, butter, eggs, fresh ginge...\n",
       "6           spanish  42779  [olive oil, salt, medium shrimp, pepper, garli...\n",
       "7           italian   3735  [sugar, pistachio nuts, white almond bark, flo...\n",
       "8           mexican  16903  [olive oil, purple onion, fresh pineapple, por...\n",
       "9           italian  12734  [chopped tomatoes, fresh basil, garlic, extra-...\n",
       "10          italian   5875  [pimentos, sweet pepper, dried oregano, olive ...\n",
       "11          chinese  45887  [low sodium soy sauce, fresh ginger, dry musta...\n",
       "12          italian   2698  [Italian parsley leaves, walnuts, hot red pepp...\n",
       "13          mexican  41995  [ground cinnamon, fresh cilantro, chili powder...\n",
       "14          italian  31908  [fresh parmesan cheese, butter, all-purpose fl...\n",
       "15           indian  24717  [tumeric, vegetable stock, tomatoes, garam mas...\n",
       "16          british  34466  [greek yogurt, lemon curd, confectioners sugar...\n",
       "17          italian   1420  [italian seasoning, broiler-fryer chicken, may...\n",
       "18             thai   2941   [sugar, hot chili, asian fish sauce, lime juice]\n",
       "19       vietnamese   8152  [soy sauce, vegetable oil, red bell pepper, ch...\n",
       "20             thai  13121  [pork loin, roasted peanuts, chopped cilantro ...\n",
       "21          mexican  40523  [roma tomatoes, kosher salt, purple onion, jal...\n",
       "22      southern_us  40989  [low-fat mayonnaise, pepper, salt, baking pota...\n",
       "23          chinese  29630  [sesame seeds, red pepper, yellow peppers, wat...\n",
       "24          italian  49136  [marinara sauce, flat leaf parsley, olive oil,...\n",
       "25          chinese  26705  [sugar, lo mein noodles, salt, chicken broth, ...\n",
       "26     cajun_creole  27976  [herbs, lemon juice, fresh tomatoes, paprika, ...\n",
       "27          italian  22087  [ground black pepper, butter, sliced mushrooms...\n",
       "28          chinese   9197  [green bell pepper, egg roll wrappers, sweet a...\n",
       "29          mexican   1299  [flour tortillas, cheese, breakfast sausages, ...\n",
       "...             ...    ...                                                ...\n",
       "39744         greek   5680  [extra-virgin olive oil, oregano, potatoes, ga...\n",
       "39745       spanish   5511  [quinoa, extra-virgin olive oil, fresh thyme l...\n",
       "39746        indian  32051  [clove, bay leaves, ginger, chopped cilantro, ...\n",
       "39747      moroccan   5119  [water, sugar, grated lemon zest, butter, pitt...\n",
       "39748       italian   9526  [sea salt, pizza doughs, all-purpose flour, co...\n",
       "39749       mexican  45599  [kosher salt, minced onion, tortilla chips, su...\n",
       "39750       mexican  49670  [ground black pepper, chicken breasts, salsa, ...\n",
       "39751      moroccan  30735  [olive oil, cayenne pepper, chopped cilantro f...\n",
       "39752   southern_us   5911  [self rising flour, milk, white sugar, butter,...\n",
       "39753       italian  33294  [rosemary sprigs, lemon zest, garlic cloves, g...\n",
       "39754    vietnamese  27082  [jasmine rice, bay leaves, sticky rice, rotiss...\n",
       "39755        indian  36337  [mint leaves, cilantro leaves, ghee, tomatoes,...\n",
       "39756       mexican  15508  [vegetable oil, cinnamon sticks, water, all-pu...\n",
       "39757         greek  34331  [red bell pepper, garlic cloves, extra-virgin ...\n",
       "39758         greek  47387  [milk, salt, ground cayenne pepper, ground lam...\n",
       "39759        korean  12153  [red chili peppers, sea salt, onions, water, c...\n",
       "39760   southern_us  41840  [butter, large eggs, cornmeal, baking powder, ...\n",
       "39761       chinese   6487  [honey, chicken breast halves, cilantro leaves...\n",
       "39762        indian  26646  [curry powder, salt, chicken, water, vegetable...\n",
       "39763       italian  44798  [fettuccine pasta, low-fat cream cheese, garli...\n",
       "39764       mexican   8089  [chili powder, worcestershire sauce, celery, r...\n",
       "39765        indian   6153  [coconut, unsweetened coconut milk, mint leave...\n",
       "39766         irish  25557  [rutabaga, ham, thick-cut bacon, potatoes, fre...\n",
       "39767       italian  24348  [low-fat sour cream, grated parmesan cheese, s...\n",
       "39768       mexican   7377  [shredded cheddar cheese, crushed cheese crack...\n",
       "39769         irish  29109  [light brown sugar, granulated sugar, butter, ...\n",
       "39770       italian  11462  [KRAFT Zesty Italian Dressing, purple onion, b...\n",
       "39771         irish   2238  [eggs, citrus fruit, raisins, sourdough starte...\n",
       "39772       chinese  41882  [boneless chicken skinless thigh, minced garli...\n",
       "39773       mexican   2362  [green chile, jalapeno chilies, onions, ground...\n",
       "\n",
       "[39774 rows x 3 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Text Features\n",
    "An important step in working with text data is to **vectorize** them somehow for input to standard optimization algorithms. First, I clean up the text input using [WordNet Lemmatization](http://textminingonline.com/dive-into-nltk-part-iv-stemming-and-lemmatization). I then use the [TfidVectorizer](http://scikit-learn.org/stable/modules/feature_extraction.html) from Scikit-learn module to vectorize the ingredient features into an array of floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vectorization of ingredients Using WordNet lemmatization & Tfid\n",
    "data['ingredients_clean_string'] = [' , '.join(z).strip() for z in data['ingredients']]  \n",
    "data['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in data['ingredients']]\n",
    "\n",
    "vectorizer  = TfidfVectorizer(stop_words='english', ngram_range=(1,1), max_df=0.57, analyzer='word', token_pattern=r'\\w+')\n",
    "x_train     = vectorizer.fit_transform(data.ingredients_string).todense()\n",
    "ingred_dict = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2963)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiting Classes\n",
    "To go easy on my machine's resources (memory and cpu), I limit the number of cuisines/classes to two or three: british(1), chinese(3) and indian(3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# limit training data: british, chinese & indian\n",
    "idx = np.logical_or(y_train==1, y_train==3)\n",
    "idx = np.logical_or(idx, y_train==7)\n",
    "idx = np.logical_or(idx, y_train==5)\n",
    "idx = np.logical_or(idx, y_train==2)\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Feature Space\n",
    "Here, I proceed to visualize the feature space using a linear dimensionality reduction technique - Principal Component Analysis (PCA), and then a non-linear one: [t-SNE](http://lvdmaaten.github.io/tsne/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize Using PCA \n",
    "t0 = time()\n",
    "x_pca = PCA(n_components=2).fit_transform(x_train)\n",
    "t1 = time()\n",
    "print(\"PCA: %.2g sec\" % (t1 - t0))\n",
    "figure()\n",
    "ccm = cm.get_cmap('RdYlBu')\n",
    "scatter(x_pca[:,0], x_pca[:,1], c=y_train, cmap=ccm)\n",
    "title('PCA Visualization of Cuisines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize Using t-SNE\n",
    "print(\"Computing t-SNE embedding\")\n",
    "t0 = time()\n",
    "tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
    "x_tsne = tsne.fit_transform(x_train)\n",
    "t1 = time()\n",
    "print(\"t-SNE: %.2g sec\" % (t1 - t0))\n",
    "figure()\n",
    "scatter(x_tsne[:,0], x_tsne[:,1], c=y_train, cmap=ccm)\n",
    "title('t-SNE Visualization of Cuisines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
